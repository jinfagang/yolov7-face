7767517
360 368
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,640,640)f32
nn.Conv2d                model.0.conv             1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(32)f32 @weight=(32,3,3,3)f32 #0=(1,3,640,640)f32 #1=(1,32,320,320)f32
nn.LeakyReLU             model.0.act              1 1 1 2 negative_slope=1.000000e-01 #1=(1,32,320,320)f32 #2=(1,32,320,320)f32
nn.Conv2d                model.1.conv             1 1 2 3 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(64)f32 @weight=(64,32,3,3)f32 #2=(1,32,320,320)f32 #3=(1,64,160,160)f32
nn.LeakyReLU             model.1.act              1 1 3 4 negative_slope=1.000000e-01 #3=(1,64,160,160)f32 #4=(1,64,160,160)f32
nn.Conv2d                model.2.conv             1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #4=(1,64,160,160)f32 #5=(1,32,160,160)f32
nn.LeakyReLU             model.2.act              1 1 5 6 negative_slope=1.000000e-01 #5=(1,32,160,160)f32 #6=(1,32,160,160)f32
nn.Conv2d                model.3.conv             1 1 4 7 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #4=(1,64,160,160)f32 #7=(1,32,160,160)f32
nn.LeakyReLU             model.3.act              1 1 7 8 negative_slope=1.000000e-01 #7=(1,32,160,160)f32 #8=(1,32,160,160)f32
nn.Conv2d                model.4.conv             1 1 8 9 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #8=(1,32,160,160)f32 #9=(1,32,160,160)f32
nn.LeakyReLU             model.4.act              1 1 9 10 negative_slope=1.000000e-01 #9=(1,32,160,160)f32 #10=(1,32,160,160)f32
nn.Conv2d                model.5.conv             1 1 10 11 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #10=(1,32,160,160)f32 #11=(1,32,160,160)f32
nn.LeakyReLU             model.5.act              1 1 11 12 negative_slope=1.000000e-01 #11=(1,32,160,160)f32 #12=(1,32,160,160)f32
torch.cat                torch.cat_120            4 1 12 10 8 6 13 dim=1 #12=(1,32,160,160)f32 #10=(1,32,160,160)f32 #8=(1,32,160,160)f32 #6=(1,32,160,160)f32 #13=(1,128,160,160)f32
nn.Conv2d                model.7.conv             1 1 13 14 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,1,1)f32 #13=(1,128,160,160)f32 #14=(1,64,160,160)f32
nn.LeakyReLU             model.7.act              1 1 14 15 negative_slope=1.000000e-01 #14=(1,64,160,160)f32 #15=(1,64,160,160)f32
nn.MaxPool2d             model.8.m                1 1 15 16 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #15=(1,64,160,160)f32 #16=(1,64,80,80)f32
nn.Conv2d                model.9.conv             1 1 16 17 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #16=(1,64,80,80)f32 #17=(1,64,80,80)f32
nn.LeakyReLU             model.9.act              1 1 17 18 negative_slope=1.000000e-01 #17=(1,64,80,80)f32 #18=(1,64,80,80)f32
nn.Conv2d                model.10.conv            1 1 16 19 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #16=(1,64,80,80)f32 #19=(1,64,80,80)f32
nn.LeakyReLU             model.10.act             1 1 19 20 negative_slope=1.000000e-01 #19=(1,64,80,80)f32 #20=(1,64,80,80)f32
nn.Conv2d                model.11.conv            1 1 20 21 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #20=(1,64,80,80)f32 #21=(1,64,80,80)f32
nn.LeakyReLU             model.11.act             1 1 21 22 negative_slope=1.000000e-01 #21=(1,64,80,80)f32 #22=(1,64,80,80)f32
nn.Conv2d                model.12.conv            1 1 22 23 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #22=(1,64,80,80)f32 #23=(1,64,80,80)f32
nn.LeakyReLU             model.12.act             1 1 23 24 negative_slope=1.000000e-01 #23=(1,64,80,80)f32 #24=(1,64,80,80)f32
torch.cat                torch.cat_121            4 1 24 22 20 18 25 dim=1 #24=(1,64,80,80)f32 #22=(1,64,80,80)f32 #20=(1,64,80,80)f32 #18=(1,64,80,80)f32 #25=(1,256,80,80)f32
nn.Conv2d                model.14.conv            1 1 25 26 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #25=(1,256,80,80)f32 #26=(1,128,80,80)f32
nn.LeakyReLU             model.14.act             1 1 26 27 negative_slope=1.000000e-01 #26=(1,128,80,80)f32 #27=(1,128,80,80)f32
nn.MaxPool2d             model.15.m               1 1 27 28 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #27=(1,128,80,80)f32 #28=(1,128,40,40)f32
nn.Conv2d                model.16.conv            1 1 28 29 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #28=(1,128,40,40)f32 #29=(1,128,40,40)f32
nn.LeakyReLU             model.16.act             1 1 29 30 negative_slope=1.000000e-01 #29=(1,128,40,40)f32 #30=(1,128,40,40)f32
nn.Conv2d                model.17.conv            1 1 28 31 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #28=(1,128,40,40)f32 #31=(1,128,40,40)f32
nn.LeakyReLU             model.17.act             1 1 31 32 negative_slope=1.000000e-01 #31=(1,128,40,40)f32 #32=(1,128,40,40)f32
nn.Conv2d                model.18.conv            1 1 32 33 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 #32=(1,128,40,40)f32 #33=(1,128,40,40)f32
nn.LeakyReLU             model.18.act             1 1 33 34 negative_slope=1.000000e-01 #33=(1,128,40,40)f32 #34=(1,128,40,40)f32
nn.Conv2d                model.19.conv            1 1 34 35 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 #34=(1,128,40,40)f32 #35=(1,128,40,40)f32
nn.LeakyReLU             model.19.act             1 1 35 36 negative_slope=1.000000e-01 #35=(1,128,40,40)f32 #36=(1,128,40,40)f32
torch.cat                torch.cat_122            4 1 36 34 32 30 37 dim=1 #36=(1,128,40,40)f32 #34=(1,128,40,40)f32 #32=(1,128,40,40)f32 #30=(1,128,40,40)f32 #37=(1,512,40,40)f32
nn.Conv2d                model.21.conv            1 1 37 38 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,512,1,1)f32 #37=(1,512,40,40)f32 #38=(1,256,40,40)f32
nn.LeakyReLU             model.21.act             1 1 38 39 negative_slope=1.000000e-01 #38=(1,256,40,40)f32 #39=(1,256,40,40)f32
nn.MaxPool2d             model.22.m               1 1 39 40 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #39=(1,256,40,40)f32 #40=(1,256,20,20)f32
nn.Conv2d                model.23.conv            1 1 40 41 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #40=(1,256,20,20)f32 #41=(1,256,20,20)f32
nn.LeakyReLU             model.23.act             1 1 41 42 negative_slope=1.000000e-01 #41=(1,256,20,20)f32 #42=(1,256,20,20)f32
nn.Conv2d                model.24.conv            1 1 40 43 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #40=(1,256,20,20)f32 #43=(1,256,20,20)f32
nn.LeakyReLU             model.24.act             1 1 43 44 negative_slope=1.000000e-01 #43=(1,256,20,20)f32 #44=(1,256,20,20)f32
nn.Conv2d                model.25.conv            1 1 44 45 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 #44=(1,256,20,20)f32 #45=(1,256,20,20)f32
nn.LeakyReLU             model.25.act             1 1 45 46 negative_slope=1.000000e-01 #45=(1,256,20,20)f32 #46=(1,256,20,20)f32
nn.Conv2d                model.26.conv            1 1 46 47 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 #46=(1,256,20,20)f32 #47=(1,256,20,20)f32
nn.LeakyReLU             model.26.act             1 1 47 48 negative_slope=1.000000e-01 #47=(1,256,20,20)f32 #48=(1,256,20,20)f32
torch.cat                torch.cat_123            4 1 48 46 44 42 49 dim=1 #48=(1,256,20,20)f32 #46=(1,256,20,20)f32 #44=(1,256,20,20)f32 #42=(1,256,20,20)f32 #49=(1,1024,20,20)f32
nn.Conv2d                model.28.conv            1 1 49 50 bias=True dilation=(1,1) groups=1 in_channels=1024 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1024,1,1)f32 #49=(1,1024,20,20)f32 #50=(1,512,20,20)f32
nn.LeakyReLU             model.28.act             1 1 50 51 negative_slope=1.000000e-01 #50=(1,512,20,20)f32 #51=(1,512,20,20)f32
nn.Conv2d                model.29.conv            1 1 51 52 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,512,1,1)f32 #51=(1,512,20,20)f32 #52=(1,256,20,20)f32
nn.LeakyReLU             model.29.act             1 1 52 53 negative_slope=1.000000e-01 #52=(1,256,20,20)f32 #53=(1,256,20,20)f32
nn.Conv2d                model.30.conv            1 1 51 54 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,512,1,1)f32 #51=(1,512,20,20)f32 #54=(1,256,20,20)f32
nn.LeakyReLU             model.30.act             1 1 54 55 negative_slope=1.000000e-01 #54=(1,256,20,20)f32 #55=(1,256,20,20)f32
nn.MaxPool2d             model.31.m               1 1 55 56 ceil_mode=False dilation=(1,1) kernel_size=(5,5) padding=(2,2) return_indices=False stride=(1,1) #55=(1,256,20,20)f32 #56=(1,256,20,20)f32
nn.MaxPool2d             model.32.m               1 1 55 57 ceil_mode=False dilation=(1,1) kernel_size=(9,9) padding=(4,4) return_indices=False stride=(1,1) #55=(1,256,20,20)f32 #57=(1,256,20,20)f32
nn.MaxPool2d             model.33.m               1 1 55 58 ceil_mode=False dilation=(1,1) kernel_size=(13,13) padding=(6,6) return_indices=False stride=(1,1) #55=(1,256,20,20)f32 #58=(1,256,20,20)f32
torch.cat                torch.cat_124            4 1 58 57 56 55 59 dim=1 #58=(1,256,20,20)f32 #57=(1,256,20,20)f32 #56=(1,256,20,20)f32 #55=(1,256,20,20)f32 #59=(1,1024,20,20)f32
nn.Conv2d                model.35.conv            1 1 59 60 bias=True dilation=(1,1) groups=1 in_channels=1024 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1024,1,1)f32 #59=(1,1024,20,20)f32 #60=(1,256,20,20)f32
nn.LeakyReLU             model.35.act             1 1 60 61 negative_slope=1.000000e-01 #60=(1,256,20,20)f32 #61=(1,256,20,20)f32
torch.cat                torch.cat_125            2 1 61 53 62 dim=1 #61=(1,256,20,20)f32 #53=(1,256,20,20)f32 #62=(1,512,20,20)f32
nn.Conv2d                model.37.conv            1 1 62 63 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,512,1,1)f32 #62=(1,512,20,20)f32 #63=(1,256,20,20)f32
nn.LeakyReLU             model.37.act             1 1 63 64 negative_slope=1.000000e-01 #63=(1,256,20,20)f32 #64=(1,256,20,20)f32
nn.Conv2d                model.38.conv            1 1 64 65 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #64=(1,256,20,20)f32 #65=(1,128,20,20)f32
nn.LeakyReLU             model.38.act             1 1 65 66 negative_slope=1.000000e-01 #65=(1,128,20,20)f32 #66=(1,128,20,20)f32
nn.Upsample              model.39                 1 1 66 67 mode=nearest scale_factor=(2.000000e+00,2.000000e+00) size=None #66=(1,128,20,20)f32 #67=(1,128,40,40)f32
nn.Conv2d                model.40.conv            1 1 39 68 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #39=(1,256,40,40)f32 #68=(1,128,40,40)f32
nn.LeakyReLU             model.40.act             1 1 68 69 negative_slope=1.000000e-01 #68=(1,128,40,40)f32 #69=(1,128,40,40)f32
torch.cat                torch.cat_126            2 1 69 67 70 dim=1 #69=(1,128,40,40)f32 #67=(1,128,40,40)f32 #70=(1,256,40,40)f32
nn.Conv2d                model.42.conv            1 1 70 71 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,256,1,1)f32 #70=(1,256,40,40)f32 #71=(1,64,40,40)f32
nn.LeakyReLU             model.42.act             1 1 71 72 negative_slope=1.000000e-01 #71=(1,64,40,40)f32 #72=(1,64,40,40)f32
nn.Conv2d                model.43.conv            1 1 70 73 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,256,1,1)f32 #70=(1,256,40,40)f32 #73=(1,64,40,40)f32
nn.LeakyReLU             model.43.act             1 1 73 74 negative_slope=1.000000e-01 #73=(1,64,40,40)f32 #74=(1,64,40,40)f32
nn.Conv2d                model.44.conv            1 1 74 75 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #74=(1,64,40,40)f32 #75=(1,64,40,40)f32
nn.LeakyReLU             model.44.act             1 1 75 76 negative_slope=1.000000e-01 #75=(1,64,40,40)f32 #76=(1,64,40,40)f32
nn.Conv2d                model.45.conv            1 1 76 77 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #76=(1,64,40,40)f32 #77=(1,64,40,40)f32
nn.LeakyReLU             model.45.act             1 1 77 78 negative_slope=1.000000e-01 #77=(1,64,40,40)f32 #78=(1,64,40,40)f32
torch.cat                torch.cat_127            4 1 78 76 74 72 79 dim=1 #78=(1,64,40,40)f32 #76=(1,64,40,40)f32 #74=(1,64,40,40)f32 #72=(1,64,40,40)f32 #79=(1,256,40,40)f32
nn.Conv2d                model.47.conv            1 1 79 80 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #79=(1,256,40,40)f32 #80=(1,128,40,40)f32
nn.LeakyReLU             model.47.act             1 1 80 81 negative_slope=1.000000e-01 #80=(1,128,40,40)f32 #81=(1,128,40,40)f32
nn.Conv2d                model.48.conv            1 1 81 82 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,1,1)f32 #81=(1,128,40,40)f32 #82=(1,64,40,40)f32
nn.LeakyReLU             model.48.act             1 1 82 83 negative_slope=1.000000e-01 #82=(1,64,40,40)f32 #83=(1,64,40,40)f32
nn.Upsample              model.49                 1 1 83 84 mode=nearest scale_factor=(2.000000e+00,2.000000e+00) size=None #83=(1,64,40,40)f32 #84=(1,64,80,80)f32
nn.Conv2d                model.50.conv            1 1 27 85 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,1,1)f32 #27=(1,128,80,80)f32 #85=(1,64,80,80)f32
nn.LeakyReLU             model.50.act             1 1 85 86 negative_slope=1.000000e-01 #85=(1,64,80,80)f32 #86=(1,64,80,80)f32
torch.cat                torch.cat_128            2 1 86 84 87 dim=1 #86=(1,64,80,80)f32 #84=(1,64,80,80)f32 #87=(1,128,80,80)f32
nn.Conv2d                model.52.conv            1 1 87 88 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,128,1,1)f32 #87=(1,128,80,80)f32 #88=(1,32,80,80)f32
nn.LeakyReLU             model.52.act             1 1 88 89 negative_slope=1.000000e-01 #88=(1,32,80,80)f32 #89=(1,32,80,80)f32
nn.Conv2d                model.53.conv            1 1 87 90 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,128,1,1)f32 #87=(1,128,80,80)f32 #90=(1,32,80,80)f32
nn.LeakyReLU             model.53.act             1 1 90 91 negative_slope=1.000000e-01 #90=(1,32,80,80)f32 #91=(1,32,80,80)f32
nn.Conv2d                model.54.conv            1 1 91 92 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #91=(1,32,80,80)f32 #92=(1,32,80,80)f32
nn.LeakyReLU             model.54.act             1 1 92 93 negative_slope=1.000000e-01 #92=(1,32,80,80)f32 #93=(1,32,80,80)f32
nn.Conv2d                model.55.conv            1 1 93 94 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #93=(1,32,80,80)f32 #94=(1,32,80,80)f32
nn.LeakyReLU             model.55.act             1 1 94 95 negative_slope=1.000000e-01 #94=(1,32,80,80)f32 #95=(1,32,80,80)f32
torch.cat                torch.cat_129            4 1 95 93 91 89 96 dim=1 #95=(1,32,80,80)f32 #93=(1,32,80,80)f32 #91=(1,32,80,80)f32 #89=(1,32,80,80)f32 #96=(1,128,80,80)f32
nn.Conv2d                model.57.conv            1 1 96 97 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,1,1)f32 #96=(1,128,80,80)f32 #97=(1,64,80,80)f32
nn.LeakyReLU             model.57.act             1 1 97 98 negative_slope=1.000000e-01 #97=(1,64,80,80)f32 #98=(1,64,80,80)f32
nn.Conv2d                model.58.conv            1 1 98 99 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,64,3,3)f32 #98=(1,64,80,80)f32 #99=(1,128,40,40)f32
nn.LeakyReLU             model.58.act             1 1 99 100 negative_slope=1.000000e-01 #99=(1,128,40,40)f32 #100=(1,128,40,40)f32
torch.cat                torch.cat_130            2 1 100 81 101 dim=1 #100=(1,128,40,40)f32 #81=(1,128,40,40)f32 #101=(1,256,40,40)f32
nn.Conv2d                model.60.conv            1 1 101 102 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,256,1,1)f32 #101=(1,256,40,40)f32 #102=(1,64,40,40)f32
nn.LeakyReLU             model.60.act             1 1 102 103 negative_slope=1.000000e-01 #102=(1,64,40,40)f32 #103=(1,64,40,40)f32
nn.Conv2d                model.61.conv            1 1 101 104 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,256,1,1)f32 #101=(1,256,40,40)f32 #104=(1,64,40,40)f32
nn.LeakyReLU             model.61.act             1 1 104 105 negative_slope=1.000000e-01 #104=(1,64,40,40)f32 #105=(1,64,40,40)f32
nn.Conv2d                model.62.conv            1 1 105 106 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #105=(1,64,40,40)f32 #106=(1,64,40,40)f32
nn.LeakyReLU             model.62.act             1 1 106 107 negative_slope=1.000000e-01 #106=(1,64,40,40)f32 #107=(1,64,40,40)f32
nn.Conv2d                model.63.conv            1 1 107 108 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #107=(1,64,40,40)f32 #108=(1,64,40,40)f32
nn.LeakyReLU             model.63.act             1 1 108 109 negative_slope=1.000000e-01 #108=(1,64,40,40)f32 #109=(1,64,40,40)f32
torch.cat                torch.cat_131            4 1 109 107 105 103 110 dim=1 #109=(1,64,40,40)f32 #107=(1,64,40,40)f32 #105=(1,64,40,40)f32 #103=(1,64,40,40)f32 #110=(1,256,40,40)f32
nn.Conv2d                model.65.conv            1 1 110 111 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #110=(1,256,40,40)f32 #111=(1,128,40,40)f32
nn.LeakyReLU             model.65.act             1 1 111 112 negative_slope=1.000000e-01 #111=(1,128,40,40)f32 #112=(1,128,40,40)f32
nn.Conv2d                model.66.conv            1 1 112 113 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(256)f32 @weight=(256,128,3,3)f32 #112=(1,128,40,40)f32 #113=(1,256,20,20)f32
nn.LeakyReLU             model.66.act             1 1 113 114 negative_slope=1.000000e-01 #113=(1,256,20,20)f32 #114=(1,256,20,20)f32
torch.cat                torch.cat_132            2 1 114 64 115 dim=1 #114=(1,256,20,20)f32 #64=(1,256,20,20)f32 #115=(1,512,20,20)f32
nn.Conv2d                model.68.conv            1 1 115 116 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,512,1,1)f32 #115=(1,512,20,20)f32 #116=(1,128,20,20)f32
nn.LeakyReLU             model.68.act             1 1 116 117 negative_slope=1.000000e-01 #116=(1,128,20,20)f32 #117=(1,128,20,20)f32
nn.Conv2d                model.69.conv            1 1 115 118 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,512,1,1)f32 #115=(1,512,20,20)f32 #118=(1,128,20,20)f32
nn.LeakyReLU             model.69.act             1 1 118 119 negative_slope=1.000000e-01 #118=(1,128,20,20)f32 #119=(1,128,20,20)f32
nn.Conv2d                model.70.conv            1 1 119 120 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 #119=(1,128,20,20)f32 #120=(1,128,20,20)f32
nn.LeakyReLU             model.70.act             1 1 120 121 negative_slope=1.000000e-01 #120=(1,128,20,20)f32 #121=(1,128,20,20)f32
nn.Conv2d                model.71.conv            1 1 121 122 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 #121=(1,128,20,20)f32 #122=(1,128,20,20)f32
nn.LeakyReLU             model.71.act             1 1 122 123 negative_slope=1.000000e-01 #122=(1,128,20,20)f32 #123=(1,128,20,20)f32
torch.cat                torch.cat_133            4 1 123 121 119 117 124 dim=1 #123=(1,128,20,20)f32 #121=(1,128,20,20)f32 #119=(1,128,20,20)f32 #117=(1,128,20,20)f32 #124=(1,512,20,20)f32
nn.Conv2d                model.73.conv            1 1 124 125 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,512,1,1)f32 #124=(1,512,20,20)f32 #125=(1,256,20,20)f32
nn.LeakyReLU             model.73.act             1 1 125 126 negative_slope=1.000000e-01 #125=(1,256,20,20)f32 #126=(1,256,20,20)f32
nn.Conv2d                model.74.conv            1 1 98 127 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,64,3,3)f32 #98=(1,64,80,80)f32 #127=(1,128,80,80)f32
nn.LeakyReLU             model.74.act             1 1 127 128 negative_slope=1.000000e-01 #127=(1,128,80,80)f32 #128=(1,128,80,80)f32
nn.Conv2d                model.75.conv            1 1 112 129 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,128,3,3)f32 #112=(1,128,40,40)f32 #129=(1,256,40,40)f32
nn.LeakyReLU             model.75.act             1 1 129 130 negative_slope=1.000000e-01 #129=(1,256,40,40)f32 #130=(1,256,40,40)f32
nn.Conv2d                model.76.conv            1 1 126 131 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,256,3,3)f32 #126=(1,256,20,20)f32 #131=(1,512,20,20)f32
nn.LeakyReLU             model.76.act             1 1 131 132 negative_slope=1.000000e-01 #131=(1,512,20,20)f32 #132=(1,512,20,20)f32
pnnx.Attribute           pnnx_45                  0 1 133 @pnnx_45=(3)f32 #133=(3)f32
pnnx.Attribute           model.77.ia.0            0 1 134 @implicit=(1,128,1,1)f32 #134=(1,128,1,1)f32
Tensor.repeat            Tensor.repeat_39         1 1 134 135 sizes=(1,1,80,80) $input=134 #134=(1,128,1,1)f32 #135=(1,128,80,80)f32
BinaryOp                 add_0                    2 1 135 128 136 0=0 #135=(1,128,80,80)f32 #128=(1,128,80,80)f32 #136=(1,128,80,80)f32
nn.Conv2d                model.77.m.0             1 1 136 137 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=18 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(18)f32 @weight=(18,128,1,1)f32 #136=(1,128,80,80)f32 #137=(1,18,80,80)f32
pnnx.Attribute           model.77.im.0            0 1 138 @implicit=(1,18,1,1)f32 #138=(1,18,1,1)f32
Tensor.repeat            Tensor.repeat_40         1 1 138 139 sizes=(1,1,80,80) $input=138 #138=(1,18,1,1)f32 #139=(1,18,80,80)f32
BinaryOp                 mul_1                    2 1 139 137 140 0=2 #139=(1,18,80,80)f32 #137=(1,18,80,80)f32 #140=(1,18,80,80)f32
nn.Conv2d                model.77.m_kpt.0.0.conv  1 1 128 141 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #128=(1,128,80,80)f32 #141=(1,128,80,80)f32
F.silu                   F.silu_0                 1 1 141 142 $input=141 #141=(1,128,80,80)f32 #142=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.1.conv  1 1 142 143 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #142=(1,128,80,80)f32 #143=(1,128,80,80)f32
F.silu                   F.silu_1                 1 1 143 144 $input=143 #143=(1,128,80,80)f32 #144=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.2.conv  1 1 144 145 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #144=(1,128,80,80)f32 #145=(1,128,80,80)f32
F.silu                   F.silu_2                 1 1 145 146 $input=145 #145=(1,128,80,80)f32 #146=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.3.conv  1 1 146 147 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #146=(1,128,80,80)f32 #147=(1,128,80,80)f32
F.silu                   F.silu_3                 1 1 147 148 $input=147 #147=(1,128,80,80)f32 #148=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.4.conv  1 1 148 149 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #148=(1,128,80,80)f32 #149=(1,128,80,80)f32
F.silu                   F.silu_4                 1 1 149 150 $input=149 #149=(1,128,80,80)f32 #150=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.5.conv  1 1 150 151 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #150=(1,128,80,80)f32 #151=(1,128,80,80)f32
F.silu                   F.silu_5                 1 1 151 152 $input=151 #151=(1,128,80,80)f32 #152=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.6.conv  1 1 152 153 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #152=(1,128,80,80)f32 #153=(1,128,80,80)f32
F.silu                   F.silu_6                 1 1 153 154 $input=153 #153=(1,128,80,80)f32 #154=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.7.conv  1 1 154 155 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #154=(1,128,80,80)f32 #155=(1,128,80,80)f32
F.silu                   F.silu_7                 1 1 155 156 $input=155 #155=(1,128,80,80)f32 #156=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.8.conv  1 1 156 157 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #156=(1,128,80,80)f32 #157=(1,128,80,80)f32
F.silu                   F.silu_8                 1 1 157 158 $input=157 #157=(1,128,80,80)f32 #158=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.9.conv  1 1 158 159 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #158=(1,128,80,80)f32 #159=(1,128,80,80)f32
F.silu                   F.silu_9                 1 1 159 160 $input=159 #159=(1,128,80,80)f32 #160=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.10.conv 1 1 160 161 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #160=(1,128,80,80)f32 #161=(1,128,80,80)f32
F.silu                   F.silu_10                1 1 161 162 $input=161 #161=(1,128,80,80)f32 #162=(1,128,80,80)f32
nn.Conv2d                model.77.m_kpt.0.11      1 1 162 163 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=45 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(45)f32 @weight=(45,128,1,1)f32 #162=(1,128,80,80)f32 #163=(1,45,80,80)f32
torch.cat                torch.cat_134            2 1 140 163 164 dim=1 #140=(1,18,80,80)f32 #163=(1,45,80,80)f32 #164=(1,63,80,80)f32
Tensor.view              Tensor.view_96           1 1 164 165 shape=(1,3,21,80,80) $input=164 #164=(1,63,80,80)f32 #165=(1,3,21,80,80)f32
torch.permute            torch.permute_144        1 1 165 166 dims=(0,1,3,4,2) $input=165 #165=(1,3,21,80,80)f32 #166=(1,3,80,80,21)f32
torch.tensor_split       slice_0                  1 2 166 167 168 dim=4 indices=(6) #166=(1,3,80,80,21)f32 #167=(1,3,80,80,6)f32 #168=(1,3,80,80,15)f32
F.sigmoid                F.sigmoid_33             1 1 167 169 $input=167 #167=(1,3,80,80,6)f32 #169=(1,3,80,80,6)f32
Tensor.view              Tensor.view_97           1 1 169 170 shape=(1,3,-1,6) $input=169 #169=(1,3,80,80,6)f32 #170=(1,3,6400,6)f32
pnnx.Attribute           pnnx_fold_grid_i_seq.1   0 1 171 @pnnx_fold_grid_i_seq.1=(1,1,6400,2)f32 #171=(1,1,6400,2)f32
Tensor.select            Tensor.select_54         1 1 133 172 dim=0 index=0 $input=133 #133=(3)f32
torch.tensor_split       slice_3                  1 3 170 173 174 175 dim=3 indices=(2,4) #170=(1,3,6400,6)f32 #173=(1,3,6400,2)f32 #174=(1,3,6400,2)f32 #175=(1,3,6400,2)f32
BinaryOp                 mul_2                    1 1 173 176 0=2 1=1 2=2.000000e+00 #173=(1,3,6400,2)f32
BinaryOp                 sub_3                    1 1 176 177 0=1 1=1 2=5.000000e-01
BinaryOp                 add_4                    2 1 177 171 178 0=0 #171=(1,1,6400,2)f32
BinaryOp                 mul_5                    2 1 178 172 179 0=2 #179=(1,3,6400,2)f32
pnnx.Attribute           pnnx_fold_1027           0 1 180 @pnnx_fold_1027=(1,3,1,2)f32 #180=(1,3,1,2)f32
BinaryOp                 mul_6                    1 1 174 181 0=2 1=1 2=2.000000e+00 #174=(1,3,6400,2)f32
BinaryOp                 pow_7                    1 1 181 182 0=6 1=1 2=2.000000e+00
BinaryOp                 mul_8                    2 1 182 180 183 0=2 #180=(1,3,1,2)f32 #183=(1,3,6400,2)f32
Tensor.view              Tensor.view_102          1 1 168 184 shape=(1,3,-1,15) $input=168 #168=(1,3,80,80,15)f32 #184=(1,3,6400,15)f32
pnnx.Attribute           pnnx_fold_1035           0 1 185 @pnnx_fold_1035=(1,1,6400,5)f32 #185=(1,1,6400,5)f32
pnnx.Attribute           pnnx_230                 0 1 186 @pnnx_230=(3)f32 #186=(3)f32
Tensor.select            Tensor.select_56         1 1 186 187 dim=0 index=0 $input=186 #186=(3)f32
Tensor.slice             slice_6                  1 1 184 188 dims=(3) ends=(2147483647) starts=(0) steps=(3) $input=184 #184=(1,3,6400,15)f32 #188=(1,3,6400,5)f32
BinaryOp                 mul_9                    1 1 188 189 0=2 1=1 2=2.000000e+00 #188=(1,3,6400,5)f32
BinaryOp                 sub_10                   1 1 189 190 0=1 1=1 2=5.000000e-01
BinaryOp                 add_11                   2 1 190 185 191 0=0 #185=(1,1,6400,5)f32
BinaryOp                 mul_12                   2 1 191 187 192 0=2 #192=(1,3,6400,5)f32
pnnx.Attribute           pnnx_fold_1043           0 1 193 @pnnx_fold_1043=(1,1,6400,5)f32 #193=(1,1,6400,5)f32
pnnx.Attribute           pnnx_253                 0 1 194 @pnnx_253=(3)f32 #194=(3)f32
Tensor.select            Tensor.select_57         1 1 194 195 dim=0 index=0 $input=194 #194=(3)f32
Tensor.slice             slice_7                  1 1 184 196 dims=(3) ends=(2147483647) starts=(1) steps=(3) $input=184 #184=(1,3,6400,15)f32 #196=(1,3,6400,5)f32
BinaryOp                 mul_13                   1 1 196 197 0=2 1=1 2=2.000000e+00 #196=(1,3,6400,5)f32
BinaryOp                 sub_14                   1 1 197 198 0=1 1=1 2=5.000000e-01
BinaryOp                 add_15                   2 1 198 193 199 0=0 #193=(1,1,6400,5)f32
BinaryOp                 mul_16                   2 1 199 195 200 0=2 #200=(1,3,6400,5)f32
Tensor.slice             slice_8                  1 1 184 201 dims=(3) ends=(2147483647) starts=(2) steps=(3) $input=184 #184=(1,3,6400,15)f32 #201=(1,3,6400,5)f32
F.sigmoid                F.sigmoid_34             1 1 201 202 $input=201 #201=(1,3,6400,5)f32 #202=(1,3,6400,5)f32
torch.unsqueeze          torch.unsqueeze_152      1 1 202 203 dim=-2 $input=202 #202=(1,3,6400,5)f32 #203=(1,3,6400,1,5)f32
torch.unsqueeze          torch.unsqueeze_151      1 1 200 204 dim=-2 $input=200 #200=(1,3,6400,5)f32 #204=(1,3,6400,1,5)f32
torch.unsqueeze          torch.unsqueeze_150      1 1 192 205 dim=-2 $input=192 #192=(1,3,6400,5)f32 #205=(1,3,6400,1,5)f32
torch.cat                torch.cat_135            3 1 205 204 203 206 dim=-2 #205=(1,3,6400,1,5)f32 #204=(1,3,6400,1,5)f32 #203=(1,3,6400,1,5)f32 #206=(1,3,6400,3,5)f32
torch.permute            torch.permute_145        1 1 206 207 dims=(0,1,2,4,3) $input=206 #206=(1,3,6400,3,5)f32 #207=(1,3,6400,5,3)f32
Tensor.reshape           Tensor.reshape_51        1 1 207 208 shape=(1,3,-1,15) $input=207 #207=(1,3,6400,5,3)f32 #208=(1,3,6400,15)f32
pnnx.Attribute           model.77.ia.1            0 1 209 @implicit=(1,256,1,1)f32 #209=(1,256,1,1)f32
Tensor.repeat            Tensor.repeat_43         1 1 209 210 sizes=(1,1,40,40) $input=209 #209=(1,256,1,1)f32 #210=(1,256,40,40)f32
BinaryOp                 add_17                   2 1 210 130 211 0=0 #210=(1,256,40,40)f32 #130=(1,256,40,40)f32 #211=(1,256,40,40)f32
nn.Conv2d                model.77.m.1             1 1 211 212 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=18 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(18)f32 @weight=(18,256,1,1)f32 #211=(1,256,40,40)f32 #212=(1,18,40,40)f32
pnnx.Attribute           model.77.im.1            0 1 213 @implicit=(1,18,1,1)f32 #213=(1,18,1,1)f32
Tensor.repeat            Tensor.repeat_44         1 1 213 214 sizes=(1,1,40,40) $input=213 #213=(1,18,1,1)f32 #214=(1,18,40,40)f32
BinaryOp                 mul_18                   2 1 214 212 215 0=2 #214=(1,18,40,40)f32 #212=(1,18,40,40)f32 #215=(1,18,40,40)f32
nn.Conv2d                model.77.m_kpt.1.0.conv  1 1 130 216 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #130=(1,256,40,40)f32 #216=(1,256,40,40)f32
F.silu                   F.silu_11                1 1 216 217 $input=216 #216=(1,256,40,40)f32 #217=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.1.conv  1 1 217 218 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #217=(1,256,40,40)f32 #218=(1,256,40,40)f32
F.silu                   F.silu_12                1 1 218 219 $input=218 #218=(1,256,40,40)f32 #219=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.2.conv  1 1 219 220 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #219=(1,256,40,40)f32 #220=(1,256,40,40)f32
F.silu                   F.silu_13                1 1 220 221 $input=220 #220=(1,256,40,40)f32 #221=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.3.conv  1 1 221 222 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #221=(1,256,40,40)f32 #222=(1,256,40,40)f32
F.silu                   F.silu_14                1 1 222 223 $input=222 #222=(1,256,40,40)f32 #223=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.4.conv  1 1 223 224 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #223=(1,256,40,40)f32 #224=(1,256,40,40)f32
F.silu                   F.silu_15                1 1 224 225 $input=224 #224=(1,256,40,40)f32 #225=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.5.conv  1 1 225 226 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #225=(1,256,40,40)f32 #226=(1,256,40,40)f32
F.silu                   F.silu_16                1 1 226 227 $input=226 #226=(1,256,40,40)f32 #227=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.6.conv  1 1 227 228 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #227=(1,256,40,40)f32 #228=(1,256,40,40)f32
F.silu                   F.silu_17                1 1 228 229 $input=228 #228=(1,256,40,40)f32 #229=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.7.conv  1 1 229 230 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #229=(1,256,40,40)f32 #230=(1,256,40,40)f32
F.silu                   F.silu_18                1 1 230 231 $input=230 #230=(1,256,40,40)f32 #231=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.8.conv  1 1 231 232 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #231=(1,256,40,40)f32 #232=(1,256,40,40)f32
F.silu                   F.silu_19                1 1 232 233 $input=232 #232=(1,256,40,40)f32 #233=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.9.conv  1 1 233 234 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #233=(1,256,40,40)f32 #234=(1,256,40,40)f32
F.silu                   F.silu_20                1 1 234 235 $input=234 #234=(1,256,40,40)f32 #235=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.10.conv 1 1 235 236 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #235=(1,256,40,40)f32 #236=(1,256,40,40)f32
F.silu                   F.silu_21                1 1 236 237 $input=236 #236=(1,256,40,40)f32 #237=(1,256,40,40)f32
nn.Conv2d                model.77.m_kpt.1.11      1 1 237 238 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=45 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(45)f32 @weight=(45,256,1,1)f32 #237=(1,256,40,40)f32 #238=(1,45,40,40)f32
torch.cat                torch.cat_137            2 1 215 238 239 dim=1 #215=(1,18,40,40)f32 #238=(1,45,40,40)f32 #239=(1,63,40,40)f32
Tensor.view              Tensor.view_104          1 1 239 240 shape=(1,3,21,40,40) $input=239 #239=(1,63,40,40)f32 #240=(1,3,21,40,40)f32
torch.permute            torch.permute_146        1 1 240 241 dims=(0,1,3,4,2) $input=240 #240=(1,3,21,40,40)f32 #241=(1,3,40,40,21)f32
torch.tensor_split       slice_10                 1 2 241 242 243 dim=4 indices=(6) #241=(1,3,40,40,21)f32 #242=(1,3,40,40,6)f32 #243=(1,3,40,40,15)f32
F.sigmoid                F.sigmoid_35             1 1 242 244 $input=242 #242=(1,3,40,40,6)f32 #244=(1,3,40,40,6)f32
Tensor.view              Tensor.view_105          1 1 244 245 shape=(1,3,-1,6) $input=244 #244=(1,3,40,40,6)f32 #245=(1,3,1600,6)f32
pnnx.Attribute           pnnx_fold_grid_i_seq0.1  0 1 246 @pnnx_fold_grid_i_seq0.1=(1,1,1600,2)f32 #246=(1,1,1600,2)f32
pnnx.Attribute           pnnx_433                 0 1 247 @pnnx_433=(3)f32 #247=(3)f32
Tensor.select            Tensor.select_58         1 1 247 248 dim=0 index=1 $input=247 #247=(3)f32
torch.tensor_split       slice_13                 1 3 245 249 250 251 dim=3 indices=(2,4) #245=(1,3,1600,6)f32 #249=(1,3,1600,2)f32 #250=(1,3,1600,2)f32 #251=(1,3,1600,2)f32
BinaryOp                 mul_19                   1 1 249 252 0=2 1=1 2=2.000000e+00 #249=(1,3,1600,2)f32
BinaryOp                 sub_20                   1 1 252 253 0=1 1=1 2=5.000000e-01
BinaryOp                 add_21                   2 1 253 246 254 0=0 #246=(1,1,1600,2)f32
BinaryOp                 mul_22                   2 1 254 248 255 0=2 #255=(1,3,1600,2)f32
pnnx.Attribute           pnnx_fold_1201           0 1 256 @pnnx_fold_1201=(1,3,1,2)f32 #256=(1,3,1,2)f32
BinaryOp                 mul_23                   1 1 250 257 0=2 1=1 2=2.000000e+00 #250=(1,3,1600,2)f32
BinaryOp                 pow_24                   1 1 257 258 0=6 1=1 2=2.000000e+00
BinaryOp                 mul_25                   2 1 258 256 259 0=2 #256=(1,3,1,2)f32 #259=(1,3,1600,2)f32
Tensor.view              Tensor.view_110          1 1 243 260 shape=(1,3,-1,15) $input=243 #243=(1,3,40,40,15)f32 #260=(1,3,1600,15)f32
pnnx.Attribute           pnnx_fold_1209           0 1 261 @pnnx_fold_1209=(1,1,1600,5)f32 #261=(1,1,1600,5)f32
pnnx.Attribute           pnnx_480                 0 1 262 @pnnx_480=(3)f32 #262=(3)f32
Tensor.select            Tensor.select_60         1 1 262 263 dim=0 index=1 $input=262 #262=(3)f32
Tensor.slice             slice_16                 1 1 260 264 dims=(3) ends=(2147483647) starts=(0) steps=(3) $input=260 #260=(1,3,1600,15)f32 #264=(1,3,1600,5)f32
BinaryOp                 mul_26                   1 1 264 265 0=2 1=1 2=2.000000e+00 #264=(1,3,1600,5)f32
BinaryOp                 sub_27                   1 1 265 266 0=1 1=1 2=5.000000e-01
BinaryOp                 add_28                   2 1 266 261 267 0=0 #261=(1,1,1600,5)f32
BinaryOp                 mul_29                   2 1 267 263 268 0=2 #268=(1,3,1600,5)f32
pnnx.Attribute           pnnx_fold_1217           0 1 269 @pnnx_fold_1217=(1,1,1600,5)f32 #269=(1,1,1600,5)f32
pnnx.Attribute           pnnx_503                 0 1 270 @pnnx_503=(3)f32 #270=(3)f32
Tensor.select            Tensor.select_61         1 1 270 271 dim=0 index=1 $input=270 #270=(3)f32
Tensor.slice             slice_17                 1 1 260 272 dims=(3) ends=(2147483647) starts=(1) steps=(3) $input=260 #260=(1,3,1600,15)f32 #272=(1,3,1600,5)f32
BinaryOp                 mul_30                   1 1 272 273 0=2 1=1 2=2.000000e+00 #272=(1,3,1600,5)f32
BinaryOp                 sub_31                   1 1 273 274 0=1 1=1 2=5.000000e-01
BinaryOp                 add_32                   2 1 274 269 275 0=0 #269=(1,1,1600,5)f32
BinaryOp                 mul_33                   2 1 275 271 276 0=2 #276=(1,3,1600,5)f32
Tensor.slice             slice_18                 1 1 260 277 dims=(3) ends=(2147483647) starts=(2) steps=(3) $input=260 #260=(1,3,1600,15)f32 #277=(1,3,1600,5)f32
F.sigmoid                F.sigmoid_36             1 1 277 278 $input=277 #277=(1,3,1600,5)f32 #278=(1,3,1600,5)f32
torch.unsqueeze          torch.unsqueeze_155      1 1 278 279 dim=-2 $input=278 #278=(1,3,1600,5)f32 #279=(1,3,1600,1,5)f32
torch.unsqueeze          torch.unsqueeze_154      1 1 276 280 dim=-2 $input=276 #276=(1,3,1600,5)f32 #280=(1,3,1600,1,5)f32
torch.unsqueeze          torch.unsqueeze_153      1 1 268 281 dim=-2 $input=268 #268=(1,3,1600,5)f32 #281=(1,3,1600,1,5)f32
torch.cat                torch.cat_138            3 1 281 280 279 282 dim=-2 #281=(1,3,1600,1,5)f32 #280=(1,3,1600,1,5)f32 #279=(1,3,1600,1,5)f32 #282=(1,3,1600,3,5)f32
torch.permute            torch.permute_147        1 1 282 283 dims=(0,1,2,4,3) $input=282 #282=(1,3,1600,3,5)f32 #283=(1,3,1600,5,3)f32
Tensor.reshape           Tensor.reshape_52        1 1 283 284 shape=(1,3,-1,15) $input=283 #283=(1,3,1600,5,3)f32 #284=(1,3,1600,15)f32
pnnx.Attribute           model.77.ia.2            0 1 285 @implicit=(1,512,1,1)f32 #285=(1,512,1,1)f32
Tensor.repeat            Tensor.repeat_47         1 1 285 286 sizes=(1,1,20,20) $input=285 #285=(1,512,1,1)f32 #286=(1,512,20,20)f32
BinaryOp                 add_34                   2 1 286 132 287 0=0 #286=(1,512,20,20)f32 #132=(1,512,20,20)f32 #287=(1,512,20,20)f32
nn.Conv2d                model.77.m.2             1 1 287 288 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=18 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(18)f32 @weight=(18,512,1,1)f32 #287=(1,512,20,20)f32 #288=(1,18,20,20)f32
pnnx.Attribute           model.77.im.2            0 1 289 @implicit=(1,18,1,1)f32 #289=(1,18,1,1)f32
Tensor.repeat            Tensor.repeat_48         1 1 289 290 sizes=(1,1,20,20) $input=289 #289=(1,18,1,1)f32 #290=(1,18,20,20)f32
BinaryOp                 mul_35                   2 1 290 288 291 0=2 #290=(1,18,20,20)f32 #288=(1,18,20,20)f32 #291=(1,18,20,20)f32
nn.Conv2d                model.77.m_kpt.2.0.conv  1 1 132 292 bias=True dilation=(1,1) groups=512 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1,3,3)f32 #132=(1,512,20,20)f32 #292=(1,512,20,20)f32
F.silu                   F.silu_22                1 1 292 293 $input=292 #292=(1,512,20,20)f32 #293=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.1.conv  1 1 293 294 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,1,1)f32 #293=(1,512,20,20)f32 #294=(1,512,20,20)f32
F.silu                   F.silu_23                1 1 294 295 $input=294 #294=(1,512,20,20)f32 #295=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.2.conv  1 1 295 296 bias=True dilation=(1,1) groups=512 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1,3,3)f32 #295=(1,512,20,20)f32 #296=(1,512,20,20)f32
F.silu                   F.silu_24                1 1 296 297 $input=296 #296=(1,512,20,20)f32 #297=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.3.conv  1 1 297 298 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,1,1)f32 #297=(1,512,20,20)f32 #298=(1,512,20,20)f32
F.silu                   F.silu_25                1 1 298 299 $input=298 #298=(1,512,20,20)f32 #299=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.4.conv  1 1 299 300 bias=True dilation=(1,1) groups=512 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1,3,3)f32 #299=(1,512,20,20)f32 #300=(1,512,20,20)f32
F.silu                   F.silu_26                1 1 300 301 $input=300 #300=(1,512,20,20)f32 #301=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.5.conv  1 1 301 302 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,1,1)f32 #301=(1,512,20,20)f32 #302=(1,512,20,20)f32
F.silu                   F.silu_27                1 1 302 303 $input=302 #302=(1,512,20,20)f32 #303=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.6.conv  1 1 303 304 bias=True dilation=(1,1) groups=512 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1,3,3)f32 #303=(1,512,20,20)f32 #304=(1,512,20,20)f32
F.silu                   F.silu_28                1 1 304 305 $input=304 #304=(1,512,20,20)f32 #305=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.7.conv  1 1 305 306 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,1,1)f32 #305=(1,512,20,20)f32 #306=(1,512,20,20)f32
F.silu                   F.silu_29                1 1 306 307 $input=306 #306=(1,512,20,20)f32 #307=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.8.conv  1 1 307 308 bias=True dilation=(1,1) groups=512 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1,3,3)f32 #307=(1,512,20,20)f32 #308=(1,512,20,20)f32
F.silu                   F.silu_30                1 1 308 309 $input=308 #308=(1,512,20,20)f32 #309=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.9.conv  1 1 309 310 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=512 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,1,1)f32 #309=(1,512,20,20)f32 #310=(1,512,20,20)f32
F.silu                   F.silu_31                1 1 310 311 $input=310 #310=(1,512,20,20)f32 #311=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.10.conv 1 1 311 312 bias=True dilation=(1,1) groups=512 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,1,3,3)f32 #311=(1,512,20,20)f32 #312=(1,512,20,20)f32
F.silu                   F.silu_32                1 1 312 313 $input=312 #312=(1,512,20,20)f32 #313=(1,512,20,20)f32
nn.Conv2d                model.77.m_kpt.2.11      1 1 313 314 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=45 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(45)f32 @weight=(45,512,1,1)f32 #313=(1,512,20,20)f32 #314=(1,45,20,20)f32
torch.cat                torch.cat_140            2 1 291 314 315 dim=1 #291=(1,18,20,20)f32 #314=(1,45,20,20)f32 #315=(1,63,20,20)f32
Tensor.view              Tensor.view_112          1 1 315 316 shape=(1,3,21,20,20) $input=315 #315=(1,63,20,20)f32 #316=(1,3,21,20,20)f32
torch.permute            torch.permute_148        1 1 316 317 dims=(0,1,3,4,2) $input=316 #316=(1,3,21,20,20)f32 #317=(1,3,20,20,21)f32
torch.tensor_split       slice_20                 1 2 317 318 319 dim=4 indices=(6) #317=(1,3,20,20,21)f32 #318=(1,3,20,20,6)f32 #319=(1,3,20,20,15)f32
F.sigmoid                F.sigmoid_37             1 1 318 320 $input=318 #318=(1,3,20,20,6)f32 #320=(1,3,20,20,6)f32
Tensor.view              Tensor.view_113          1 1 320 321 shape=(1,3,-1,6) $input=320 #320=(1,3,20,20,6)f32 #321=(1,3,400,6)f32
pnnx.Attribute           pnnx_fold_grid_i_seq1.1  0 1 322 @pnnx_fold_grid_i_seq1.1=(1,1,400,2)f32 #322=(1,1,400,2)f32
pnnx.Attribute           pnnx_684                 0 1 323 @pnnx_684=(3)f32 #323=(3)f32
Tensor.select            Tensor.select_62         1 1 323 324 dim=0 index=2 $input=323 #323=(3)f32
torch.tensor_split       slice_23                 1 3 321 325 326 327 dim=3 indices=(2,4) #321=(1,3,400,6)f32 #325=(1,3,400,2)f32 #326=(1,3,400,2)f32 #327=(1,3,400,2)f32
BinaryOp                 mul_36                   1 1 325 328 0=2 1=1 2=2.000000e+00 #325=(1,3,400,2)f32
BinaryOp                 sub_37                   1 1 328 329 0=1 1=1 2=5.000000e-01
BinaryOp                 add_38                   2 1 329 322 330 0=0 #322=(1,1,400,2)f32
BinaryOp                 mul_39                   2 1 330 324 331 0=2 #331=(1,3,400,2)f32
pnnx.Attribute           pnnx_fold_1375           0 1 332 @pnnx_fold_1375=(1,3,1,2)f32 #332=(1,3,1,2)f32
BinaryOp                 mul_40                   1 1 326 333 0=2 1=1 2=2.000000e+00 #326=(1,3,400,2)f32
BinaryOp                 pow_41                   1 1 333 334 0=6 1=1 2=2.000000e+00
BinaryOp                 mul_42                   2 1 334 332 335 0=2 #332=(1,3,1,2)f32 #335=(1,3,400,2)f32
Tensor.view              Tensor.view_118          1 1 319 336 shape=(1,3,-1,15) $input=319 #319=(1,3,20,20,15)f32 #336=(1,3,400,15)f32
pnnx.Attribute           pnnx_fold_1383           0 1 337 @pnnx_fold_1383=(1,1,400,5)f32 #337=(1,1,400,5)f32
pnnx.Attribute           pnnx_731                 0 1 338 @pnnx_731=(3)f32 #338=(3)f32
Tensor.select            Tensor.select_64         1 1 338 339 dim=0 index=2 $input=338 #338=(3)f32
Tensor.slice             slice_26                 1 1 336 340 dims=(3) ends=(2147483647) starts=(0) steps=(3) $input=336 #336=(1,3,400,15)f32 #340=(1,3,400,5)f32
BinaryOp                 mul_43                   1 1 340 341 0=2 1=1 2=2.000000e+00 #340=(1,3,400,5)f32
BinaryOp                 sub_44                   1 1 341 342 0=1 1=1 2=5.000000e-01
BinaryOp                 add_45                   2 1 342 337 343 0=0 #337=(1,1,400,5)f32
BinaryOp                 mul_46                   2 1 343 339 344 0=2 #344=(1,3,400,5)f32
pnnx.Attribute           pnnx_fold_1391           0 1 345 @pnnx_fold_1391=(1,1,400,5)f32 #345=(1,1,400,5)f32
pnnx.Attribute           pnnx_754                 0 1 346 @pnnx_754=(3)f32 #346=(3)f32
Tensor.select            Tensor.select_65         1 1 346 347 dim=0 index=2 $input=346 #346=(3)f32
Tensor.slice             slice_27                 1 1 336 348 dims=(3) ends=(2147483647) starts=(1) steps=(3) $input=336 #336=(1,3,400,15)f32 #348=(1,3,400,5)f32
BinaryOp                 mul_47                   1 1 348 349 0=2 1=1 2=2.000000e+00 #348=(1,3,400,5)f32
BinaryOp                 sub_48                   1 1 349 350 0=1 1=1 2=5.000000e-01
BinaryOp                 add_49                   2 1 350 345 351 0=0 #345=(1,1,400,5)f32
BinaryOp                 mul_50                   2 1 351 347 352 0=2 #352=(1,3,400,5)f32
Tensor.slice             slice_28                 1 1 336 353 dims=(3) ends=(2147483647) starts=(2) steps=(3) $input=336 #336=(1,3,400,15)f32 #353=(1,3,400,5)f32
F.sigmoid                F.sigmoid_38             1 1 353 354 $input=353 #353=(1,3,400,5)f32 #354=(1,3,400,5)f32
torch.unsqueeze          torch.unsqueeze_158      1 1 354 355 dim=-2 $input=354 #354=(1,3,400,5)f32 #355=(1,3,400,1,5)f32
torch.unsqueeze          torch.unsqueeze_157      1 1 352 356 dim=-2 $input=352 #352=(1,3,400,5)f32 #356=(1,3,400,1,5)f32
torch.unsqueeze          torch.unsqueeze_156      1 1 344 357 dim=-2 $input=344 #344=(1,3,400,5)f32 #357=(1,3,400,1,5)f32
torch.cat                torch.cat_141            3 1 357 356 355 358 dim=-2 #357=(1,3,400,1,5)f32 #356=(1,3,400,1,5)f32 #355=(1,3,400,1,5)f32 #358=(1,3,400,3,5)f32
torch.permute            torch.permute_149        1 1 358 359 dims=(0,1,2,4,3) $input=358 #358=(1,3,400,3,5)f32 #359=(1,3,400,5,3)f32
Tensor.reshape           Tensor.reshape_53        1 1 359 360 shape=(1,3,-1,15) $input=359 #359=(1,3,400,5,3)f32 #360=(1,3,400,15)f32
torch.cat                torch.cat_142            4 1 331 335 327 360 361 dim=-1 #331=(1,3,400,2)f32 #335=(1,3,400,2)f32 #327=(1,3,400,2)f32 #360=(1,3,400,15)f32 #361=(1,3,400,21)f32
Tensor.view              Tensor.view_119          1 1 361 362 shape=(1,-1,21) $input=361 #361=(1,3,400,21)f32 #362=(1,1200,21)f32
torch.cat                torch.cat_139            4 1 255 259 251 284 363 dim=-1 #255=(1,3,1600,2)f32 #259=(1,3,1600,2)f32 #251=(1,3,1600,2)f32 #284=(1,3,1600,15)f32 #363=(1,3,1600,21)f32
Tensor.view              Tensor.view_111          1 1 363 364 shape=(1,-1,21) $input=363 #363=(1,3,1600,21)f32 #364=(1,4800,21)f32
torch.cat                torch.cat_136            4 1 179 183 175 208 365 dim=-1 #179=(1,3,6400,2)f32 #183=(1,3,6400,2)f32 #175=(1,3,6400,2)f32 #208=(1,3,6400,15)f32 #365=(1,3,6400,21)f32
Tensor.view              Tensor.view_103          1 1 365 366 shape=(1,-1,21) $input=365 #365=(1,3,6400,21)f32 #366=(1,19200,21)f32
torch.cat                torch.cat_143            3 1 366 364 362 367 dim=1 #366=(1,19200,21)f32 #364=(1,4800,21)f32 #362=(1,1200,21)f32 #367=(1,25200,21)f32
pnnx.Output              pnnx_output_0            1 0 367 #367=(1,25200,21)f32
